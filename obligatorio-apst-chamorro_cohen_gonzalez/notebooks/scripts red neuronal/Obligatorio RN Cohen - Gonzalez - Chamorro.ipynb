{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from keras import backend\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import LeakyReLU\n",
    "import random\n",
    "from numpy.random import seed\n",
    "\n",
    "from funcionesAux import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_entrenamiento = 83\n",
    "indice_test = 108\n",
    "cant_pruebas = 10\n",
    "cant_meses = 24\n",
    "\n",
    "path = \"resultados_redes_neuronales_obligatorio\\\\\"\n",
    "\n",
    "columna_objetivo ='consumo_miles_m3(t)'\n",
    "\n",
    "#ordenados de menor a mayor\n",
    "\n",
    "lrs = [0.0007]\n",
    "batchs = [5]\n",
    "epochss = [300]\n",
    "\n",
    "arquitecturas = [([200, 150, 100], [50, 25])]\n",
    "\n",
    "experimentos = crearExperimentos(lrs, batchs, epochss, arquitecturas)\n",
    "\n",
    "tf.random.set_seed(40)\n",
    "random.seed(40)\n",
    "np.random.seed(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cant_meses = indice_test - indice_entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv(\"gasoil_csv.csv\",sep = ',',header = 0)\n",
    "meses = pd.read_csv(\"meses.csv\",sep = ',',header = 0)\n",
    "diasVentasRC = pd.read_csv(\"dias_venta_teoricos.csv\",sep =',',header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>consumo_miles_m3</th>\n",
       "      <th>Meses</th>\n",
       "      <th>Dias de Venta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/1/2010</td>\n",
       "      <td>68.874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/2/2010</td>\n",
       "      <td>60.128</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31/3/2010</td>\n",
       "      <td>84.494</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30/4/2010</td>\n",
       "      <td>79.147</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/5/2010</td>\n",
       "      <td>72.691</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>31/8/2020</td>\n",
       "      <td>70.691</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>30/9/2020</td>\n",
       "      <td>73.769</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>31/10/2020</td>\n",
       "      <td>81.305</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>30/11/2020</td>\n",
       "      <td>85.335</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>31/12/2020</td>\n",
       "      <td>79.887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Fecha  consumo_miles_m3     Meses  Dias de Venta\n",
       "0     31/1/2010            68.874  0.000000       1.000000\n",
       "1     28/2/2010            60.128  0.090909       0.000000\n",
       "2     31/3/2010            84.494  0.181818       0.333333\n",
       "3     30/4/2010            79.147  0.272727       0.666667\n",
       "4     31/5/2010            72.691  0.363636       1.000000\n",
       "..          ...               ...       ...            ...\n",
       "127   31/8/2020            70.691  0.636364       1.000000\n",
       "128   30/9/2020            73.769  0.727273       0.000000\n",
       "129  31/10/2020            81.305  0.818182       1.000000\n",
       "130  30/11/2020            85.335  0.909091       0.666667\n",
       "131  31/12/2020            79.887  1.000000       0.333333\n",
       "\n",
       "[132 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ESCALAMIENTO DE MESES\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(meses), columns = meses.columns)\n",
    "df_scaled\n",
    "\n",
    "#ESCALAMIENTO DE DIAS DE VENTAS reales\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "df_scaled2 = pd.DataFrame(scaler.fit_transform(diasVentasRC), columns = diasVentasRC.columns)\n",
    "df_scaled2\n",
    "\n",
    "#UNION DE DATAFRAME \"series\" y \"meses escalado\" y \"dias de venta teoricos escalados\"\n",
    "seriesF=pd.concat([series, df_scaled], axis = 1)\n",
    "seriesF=pd.concat([seriesF, df_scaled2], axis = 1)\n",
    "seriesF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>consumo_miles_m3(t-24)</th>\n",
       "      <th>Meses(t-24)</th>\n",
       "      <th>Dias de Venta(t-24)</th>\n",
       "      <th>consumo_miles_m3(t-23)</th>\n",
       "      <th>Meses(t-23)</th>\n",
       "      <th>Dias de Venta(t-23)</th>\n",
       "      <th>consumo_miles_m3(t-22)</th>\n",
       "      <th>Meses(t-22)</th>\n",
       "      <th>Dias de Venta(t-22)</th>\n",
       "      <th>...</th>\n",
       "      <th>Meses(t-3)</th>\n",
       "      <th>Dias de Venta(t-3)</th>\n",
       "      <th>consumo_miles_m3(t-2)</th>\n",
       "      <th>Meses(t-2)</th>\n",
       "      <th>Dias de Venta(t-2)</th>\n",
       "      <th>consumo_miles_m3(t-1)</th>\n",
       "      <th>Meses(t-1)</th>\n",
       "      <th>Dias de Venta(t-1)</th>\n",
       "      <th>Fecha(t)</th>\n",
       "      <th>consumo_miles_m3(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>68.874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.128</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.494</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.184</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31/1/2012</td>\n",
       "      <td>65.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>60.128</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.494</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>79.147</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>29/2/2012</td>\n",
       "      <td>68.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>84.494</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>79.147</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>72.691</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>68.499</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31/3/2012</td>\n",
       "      <td>76.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>79.147</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>72.691</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.217</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>68.499</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.230</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30/4/2012</td>\n",
       "      <td>79.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>72.691</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.217</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.817</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.230</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.642</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>31/5/2012</td>\n",
       "      <td>81.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>127</td>\n",
       "      <td>72.907</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>68.894</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>85.930</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.408</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>72.149</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>31/8/2020</td>\n",
       "      <td>70.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>128</td>\n",
       "      <td>68.894</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>85.930</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>86.293</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>72.149</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>70.691</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30/9/2020</td>\n",
       "      <td>73.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>129</td>\n",
       "      <td>85.930</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>86.293</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>71.868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>70.691</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>73.769</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31/10/2020</td>\n",
       "      <td>81.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>130</td>\n",
       "      <td>86.293</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>71.868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>73.769</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.305</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30/11/2020</td>\n",
       "      <td>85.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>131</td>\n",
       "      <td>71.868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>70.158</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.305</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85.335</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>31/12/2020</td>\n",
       "      <td>79.887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  consumo_miles_m3(t-24)  Meses(t-24)  Dias de Venta(t-24)  \\\n",
       "0       24                  68.874     0.000000             1.000000   \n",
       "1       25                  60.128     0.090909             0.000000   \n",
       "2       26                  84.494     0.181818             0.333333   \n",
       "3       27                  79.147     0.272727             0.666667   \n",
       "4       28                  72.691     0.363636             1.000000   \n",
       "..     ...                     ...          ...                  ...   \n",
       "103    127                  72.907     0.636364             0.666667   \n",
       "104    128                  68.894     0.727273             0.666667   \n",
       "105    129                  85.930     0.818182             0.333333   \n",
       "106    130                  86.293     0.909091             0.666667   \n",
       "107    131                  71.868     1.000000             1.000000   \n",
       "\n",
       "     consumo_miles_m3(t-23)  Meses(t-23)  Dias de Venta(t-23)  \\\n",
       "0                    60.128     0.090909             0.000000   \n",
       "1                    84.494     0.181818             0.333333   \n",
       "2                    79.147     0.272727             0.666667   \n",
       "3                    72.691     0.363636             1.000000   \n",
       "4                    69.217     0.454545             0.000000   \n",
       "..                      ...          ...                  ...   \n",
       "103                  68.894     0.727273             0.666667   \n",
       "104                  85.930     0.818182             0.333333   \n",
       "105                  86.293     0.909091             0.666667   \n",
       "106                  71.868     1.000000             1.000000   \n",
       "107                  63.058     0.000000             0.333333   \n",
       "\n",
       "     consumo_miles_m3(t-22)  Meses(t-22)  Dias de Venta(t-22)  ...  \\\n",
       "0                    84.494     0.181818             0.333333  ...   \n",
       "1                    79.147     0.272727             0.666667  ...   \n",
       "2                    72.691     0.363636             1.000000  ...   \n",
       "3                    69.217     0.454545             0.000000  ...   \n",
       "4                    66.817     0.545455             1.000000  ...   \n",
       "..                      ...          ...                  ...  ...   \n",
       "103                  85.930     0.818182             0.333333  ...   \n",
       "104                  86.293     0.909091             0.666667  ...   \n",
       "105                  71.868     1.000000             1.000000  ...   \n",
       "106                  63.058     0.000000             0.333333  ...   \n",
       "107                  70.158     0.090909             0.000000  ...   \n",
       "\n",
       "     Meses(t-3)  Dias de Venta(t-3)  consumo_miles_m3(t-2)  Meses(t-2)  \\\n",
       "0      0.818182            1.000000                 90.184    0.909091   \n",
       "1      0.909091            0.000000                 82.524    1.000000   \n",
       "2      1.000000            1.000000                 65.557    0.000000   \n",
       "3      0.000000            0.666667                 68.499    0.090909   \n",
       "4      0.090909            0.000000                 76.230    0.181818   \n",
       "..          ...                 ...                    ...         ...   \n",
       "103    0.363636            1.000000                 66.408    0.454545   \n",
       "104    0.454545            0.333333                 72.149    0.545455   \n",
       "105    0.545455            0.666667                 70.691    0.636364   \n",
       "106    0.636364            1.000000                 73.769    0.727273   \n",
       "107    0.727273            0.000000                 81.305    0.818182   \n",
       "\n",
       "     Dias de Venta(t-2)  consumo_miles_m3(t-1)  Meses(t-1)  \\\n",
       "0              0.000000                 82.524    1.000000   \n",
       "1              1.000000                 65.557    0.000000   \n",
       "2              0.666667                 68.499    0.090909   \n",
       "3              0.000000                 76.230    0.181818   \n",
       "4              1.000000                 79.642    0.272727   \n",
       "..                  ...                    ...         ...   \n",
       "103            0.333333                 72.149    0.545455   \n",
       "104            0.666667                 70.691    0.636364   \n",
       "105            1.000000                 73.769    0.727273   \n",
       "106            0.000000                 81.305    0.818182   \n",
       "107            1.000000                 85.335    0.909091   \n",
       "\n",
       "     Dias de Venta(t-1)    Fecha(t)  consumo_miles_m3(t)  \n",
       "0              1.000000   31/1/2012               65.557  \n",
       "1              0.666667   29/2/2012               68.499  \n",
       "2              0.000000   31/3/2012               76.230  \n",
       "3              1.000000   30/4/2012               79.642  \n",
       "4              0.666667   31/5/2012               81.502  \n",
       "..                  ...         ...                  ...  \n",
       "103            0.666667   31/8/2020               70.691  \n",
       "104            1.000000   30/9/2020               73.769  \n",
       "105            0.000000  31/10/2020               81.305  \n",
       "106            1.000000  30/11/2020               85.335  \n",
       "107            0.666667  31/12/2020               79.887  \n",
       "\n",
       "[108 rows x 75 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=24\n",
    "series=series_to_supervised(seriesF,n,1)\n",
    "series.head()\n",
    "\n",
    "series=series.drop('Fecha(t-%d)' % 1, axis=1)\n",
    "for i in range(2,n+1):\n",
    "    aux='Fecha(t-%d)' % i\n",
    "    series = series.drop(aux, axis=1)\n",
    "series.head()\n",
    "\n",
    "aux1 ='Dias de Venta(t)' \n",
    "series = series.drop(aux1, axis=1)\n",
    "\n",
    "aux2 ='Meses(t)' \n",
    "series = series.drop(aux2, axis=1)\n",
    "\n",
    "series = series.reset_index()\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = series.loc[:indice_entrenamiento]\n",
    "test_1 = series.loc[indice_entrenamiento+1:indice_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputcols = [\"Dias de Venta(t-24)\",\"consumo_miles_m3(t-24)\",\"Meses(t-24)\",\n",
    "\"Dias de Venta(t-23)\",\"consumo_miles_m3(t-23)\",\"Meses(t-23)\",\"Dias de Venta(t-22)\",\n",
    "\"consumo_miles_m3(t-22)\",\"Meses(t-22)\",\"Dias de Venta(t-21)\",\"consumo_miles_m3(t-21)\",\"Meses(t-21)\",\n",
    "\"Dias de Venta(t-20)\",\"consumo_miles_m3(t-20)\",\"Meses(t-20)\",\"Dias de Venta(t-19)\",\n",
    "\"consumo_miles_m3(t-19)\",\"Meses(t-19)\",\"Dias de Venta(t-18)\",\"consumo_miles_m3(t-18)\",\"Meses(t-18)\",\n",
    "\"Dias de Venta(t-17)\",\"consumo_miles_m3(t-17)\",\"Meses(t-17)\",\"Dias de Venta(t-16)\",\n",
    "\"consumo_miles_m3(t-16)\",\"Meses(t-16)\",\"Dias de Venta(t-15)\",\"consumo_miles_m3(t-15)\",\n",
    "\"Meses(t-15)\",\"Dias de Venta(t-14)\",\"consumo_miles_m3(t-14)\",\"Meses(t-14)\",\"Dias de Venta(t-13)\",\n",
    "\"consumo_miles_m3(t-13)\",\"Meses(t-13)\",\"Dias de Venta(t-12)\",\"consumo_miles_m3(t-12)\",\n",
    "\"Meses(t-12)\",\"Dias de Venta(t-11)\",\"consumo_miles_m3(t-11)\",\"Meses(t-11)\",\"Dias de Venta(t-10)\",\n",
    "\"consumo_miles_m3(t-10)\",\"Meses(t-10)\",\"Dias de Venta(t-9)\",\"consumo_miles_m3(t-9)\",\"Meses(t-9)\",\n",
    "\"Dias de Venta(t-8)\",\"consumo_miles_m3(t-8)\",\"Meses(t-8)\",\"Dias de Venta(t-7)\",\"consumo_miles_m3(t-7)\",\n",
    "\"Meses(t-7)\",\"Dias de Venta(t-6)\",\"consumo_miles_m3(t-6)\",\"Meses(t-6)\", \"Dias de Venta(t-5)\",\n",
    "\"consumo_miles_m3(t-5)\",\"Meses(t-5)\", \"Dias de Venta(t-4)\",\"consumo_miles_m3(t-4)\",\"Meses(t-4)\", \n",
    "\"Dias de Venta(t-3)\",\"consumo_miles_m3(t-3)\",\"Meses(t-3)\",\"Dias de Venta(t-2)\",\"consumo_miles_m3(t-2)\",\n",
    "\"Meses(t-2)\",\"Dias de Venta(t-1)\",\"consumo_miles_m3(t-1)\",\"Meses(t-1)\"]\n",
    "\n",
    "etiqueta =[\"consumo_miles_m3(t)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[inputcols].values\n",
    "y_train = train[etiqueta].values\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], n, int(x_train.shape[1]/n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_1[inputcols].values\n",
    "y_test = test_1[etiqueta].values\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], n, int(x_test.shape[1]/n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 75.8314 - rmse: 75.7373\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 2s 91ms/step - loss: 65.5615 - rmse: 65.4734\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 48.2023 - rmse: 48.1146\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 15.8408 - rmse: 15.7534\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 11.0140 - rmse: 10.9267\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 1s 82ms/step - loss: 13.0810 - rmse: 12.9938\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 14.7089 - rmse: 14.6219\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 10.6624 - rmse: 10.5757\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 10.1913 - rmse: 10.1048\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 8.5508 - rmse: 8.4645\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 2s 91ms/step - loss: 8.7912 - rmse: 8.7050\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 2s 88ms/step - loss: 10.6950 - rmse: 10.6090\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 8.8844 - rmse: 8.7987\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 7.8034 - rmse: 7.7178\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 8.0087 - rmse: 7.9231\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 1s 79ms/step - loss: 8.0379 - rmse: 7.9524\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 8.9395 - rmse: 8.8541\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 6.9333 - rmse: 6.8479\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 6.6917 - rmse: 6.6063\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 7.6500 - rmse: 7.5649\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 6.6062 - rmse: 6.5213\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 7.2279 - rmse: 7.1434\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 1s 84ms/step - loss: 6.7880 - rmse: 6.7036\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 7.0110 - rmse: 6.9268\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 6.6644 - rmse: 6.5803\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 7.4676 - rmse: 7.3836\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 7.1444 - rmse: 7.0604\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 6.9885 - rmse: 6.9048\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 6.1441 - rmse: 6.0606\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 1s 84ms/step - loss: 5.7283 - rmse: 5.6451\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 5.5472 - rmse: 5.4642\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 6.1595 - rmse: 6.0765\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 6.5316 - rmse: 6.4488\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 5.9416 - rmse: 5.8588\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 6.3382 - rmse: 6.2557\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 7.7716 - rmse: 7.6894\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 9.4222 - rmse: 9.3402\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 1s 81ms/step - loss: 8.0320 - rmse: 7.9502\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 5.6773 - rmse: 5.5954\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 5.2440 - rmse: 5.1624\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 5.8775 - rmse: 5.7961\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 2s 88ms/step - loss: 5.5012 - rmse: 5.4200\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 5.5978 - rmse: 5.5169\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 7.0771 - rmse: 6.9963\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 5.2294 - rmse: 5.1487\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 5.5059 - rmse: 5.4252\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 5.6049 - rmse: 5.5244\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 5.0719 - rmse: 4.9915\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 5.5631 - rmse: 5.4829\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 5.0652 - rmse: 4.9852\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 4.6308 - rmse: 4.5508\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 6.2937 - rmse: 6.2140\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 6.6510 - rmse: 6.5717\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 5.5612 - rmse: 5.4820\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 6.0332 - rmse: 5.9543\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 4.5920 - rmse: 4.5132\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 5.3626 - rmse: 5.2839\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 4.6364 - rmse: 4.5578\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 4.5224 - rmse: 4.4439\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 5.0069 - rmse: 4.9286\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 5.2076 - rmse: 5.1295\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 5.8669 - rmse: 5.7889\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 4.9620 - rmse: 4.8840\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 4.8310 - rmse: 4.7531\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 4.3951 - rmse: 4.3173\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 1s 84ms/step - loss: 4.8448 - rmse: 4.7671\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 6.2238 - rmse: 6.1464\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.9953 - rmse: 4.9180\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 5.5649 - rmse: 5.4876\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 6.9826 - rmse: 6.9054\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 5.2164 - rmse: 5.1394\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.5610 - rmse: 4.4842\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 4.9681 - rmse: 4.8917\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 6.7110 - rmse: 6.6347\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 5.7520 - rmse: 5.6761\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 5.4255 - rmse: 5.3499\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.3379 - rmse: 4.2626\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 4.0079 - rmse: 3.9327\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 1s 79ms/step - loss: 4.5604 - rmse: 4.4852\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 4.5508 - rmse: 4.4758\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 4.2815 - rmse: 4.2067\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 5.2738 - rmse: 5.1991\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 5.6092 - rmse: 5.5346\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 5.2347 - rmse: 5.1600\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 2s 90ms/step - loss: 5.0524 - rmse: 4.9780\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 4.5941 - rmse: 4.5200\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 4.7135 - rmse: 4.6395\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 4.5354 - rmse: 4.4615\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 4.1613 - rmse: 4.0878\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.1169 - rmse: 4.0433\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.3333 - rmse: 4.2599\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 4.2535 - rmse: 4.1803\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 4.9986 - rmse: 4.9256\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 5.5191 - rmse: 5.4461\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.5928 - rmse: 4.5200\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 4.6305 - rmse: 4.5580\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 4.3284 - rmse: 4.2559\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 4.7336 - rmse: 4.6616\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 4.6017 - rmse: 4.5298\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 1s 84ms/step - loss: 5.8652 - rmse: 5.7932\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.5124 - rmse: 4.4407\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 4.0628 - rmse: 3.9913\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 5.0841 - rmse: 5.0126\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 4.2738 - rmse: 4.2023\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 4.8571 - rmse: 4.7858\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 1s 77ms/step - loss: 4.5693 - rmse: 4.4981\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 1s 77ms/step - loss: 4.7597 - rmse: 4.6888\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 1s 78ms/step - loss: 4.4323 - rmse: 4.3616\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 3.7137 - rmse: 3.6432\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 2s 88ms/step - loss: 6.1796 - rmse: 6.1093\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 4.0568 - rmse: 3.9868\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.2567 - rmse: 4.1867\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 4.8542 - rmse: 4.7842\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 6.4683 - rmse: 6.3986\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 5.7269 - rmse: 5.6573\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 2s 88ms/step - loss: 4.3565 - rmse: 4.2871\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 3.6459 - rmse: 3.5766\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 3.7785 - rmse: 3.7094\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 3.5061 - rmse: 3.4372\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 1s 72ms/step - loss: 3.9546 - rmse: 3.8857\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 1s 84ms/step - loss: 4.3732 - rmse: 4.3043\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 3.8686 - rmse: 3.7998\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 4.3283 - rmse: 4.2597\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.0046 - rmse: 3.9362\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.1705 - rmse: 4.1022\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 3.9719 - rmse: 3.9037\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 4.2052 - rmse: 4.1371\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 5.2158 - rmse: 5.1476\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 4.9781 - rmse: 4.9099\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 5.9154 - rmse: 5.8475\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 1s 84ms/step - loss: 3.8084 - rmse: 3.7409\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 3.5488 - rmse: 3.4814\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 3.8296 - rmse: 3.7622\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.2044 - rmse: 4.1369\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 4.7080 - rmse: 4.6407\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.8157 - rmse: 4.7486\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 4.8007 - rmse: 4.7336\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 4.2350 - rmse: 4.1681\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 3.7651 - rmse: 3.6983\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 3.7243 - rmse: 3.6575\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 1s 77ms/step - loss: 4.2844 - rmse: 4.2178\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 3.1220 - rmse: 3.0555\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 2s 91ms/step - loss: 3.8385 - rmse: 3.7719\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 3.5827 - rmse: 3.5161\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 4.1457 - rmse: 4.0793\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 4.8309 - rmse: 4.7647\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 3.8268 - rmse: 3.7606\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 5.1030 - rmse: 5.0371\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 3.9319 - rmse: 3.8660\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 3.1679 - rmse: 3.1021\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 3.3595 - rmse: 3.2938\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 3.9236 - rmse: 3.8580\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 4.1831 - rmse: 4.1173\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 2s 88ms/step - loss: 3.7683 - rmse: 3.7022\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 4.3891 - rmse: 4.3230\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 3.3923 - rmse: 3.3265\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 3.7067 - rmse: 3.6412\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 1s 84ms/step - loss: 3.2499 - rmse: 3.1845\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 3.2357 - rmse: 3.1701\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 1s 78ms/step - loss: 3.3948 - rmse: 3.3293\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 3.4431 - rmse: 3.3775\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 3.1463 - rmse: 3.0805\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 5.3449 - rmse: 5.2792\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 5.7438 - rmse: 5.6785\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 3.7885 - rmse: 3.7236\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 3.8378 - rmse: 3.7732\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 3.7571 - rmse: 3.6925\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 2s 89ms/step - loss: 3.9298 - rmse: 3.8652\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 3.7585 - rmse: 3.6940\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 4.5336 - rmse: 4.4691\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 1s 86ms/step - loss: 4.2014 - rmse: 4.1367\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 3.6207 - rmse: 3.5560\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 4.2357 - rmse: 4.1711\n",
      "Epoch 174/300\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 5.9119 - rmse: 5.8473"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-913e59feb18b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodeloGasoil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mscoresGasoil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodeloGasoil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in experimentos:\n",
    "    batch = e[\"batch\"]\n",
    "    lr = e[\"learning_rate\"]\n",
    "    epochs = e[\"epochs\"]\n",
    "    lstms = e[\"arquitectura\"][0]\n",
    "    densas = e[\"arquitectura\"][1]\n",
    "\n",
    "    input_s = (x_train.shape[1], x_train.shape[2])\n",
    "    listAuxGasoil = []\n",
    "   \n",
    "    predGasoil = []\n",
    "    mgasoil = []    \n",
    "    for i in range(cant_pruebas):\n",
    "        \n",
    "        scoresMarianaGasoil = []\n",
    "\n",
    "        modeloGasoil = crearModelo(input_s,lstms,densas,1, lr, True, 0.2, 0.001)  \n",
    "        \n",
    "        \n",
    "        modeloGasoil.fit(x_train, y_train,epochs = epochs, batch_size = batch) \n",
    "        \n",
    "        scoresGasoil = modeloGasoil.evaluate(x_test,y_test)\n",
    "        predictionsGasoil = modeloGasoil.predict(x_test)\n",
    "\n",
    "        scoresMarianaGasoil.append(scoresGasoil[1])\n",
    "\n",
    "        predGasoil.append(predictionsGasoil)\n",
    "        \n",
    "        emensuales = erroresMensuales(cant_meses,predictionsGasoil,test_1[columna_objetivo])\n",
    "        mgasoil.append(emensuales)\n",
    "        \n",
    "        listAuxGasoil.append(np.mean(emensuales))\n",
    "\n",
    "    generacionArchivo(e, path,listAuxGasoil,cant_meses,predGasoil,mgasoil)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
